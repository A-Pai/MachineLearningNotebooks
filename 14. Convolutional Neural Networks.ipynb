{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.images.astype(np.float32)\n",
    "y = digits.target.astype(np.int32)\n",
    "\n",
    "# Split it into train / test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Split X_train again to create validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/hzf28kx94nv2vp_fvfsfvkdw0000gn/T/tmppjqu_zun\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 8, 8, 1), dtype=float32)\n",
      "Tensor(\"Conv/Relu:0\", shape=(?, 8, 8, 24), dtype=float32)\n",
      "Tensor(\"Max:0\", shape=(?, 24), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 8, 8, 1), dtype=float32)\n",
      "Tensor(\"Conv/Relu:0\", shape=(?, 8, 8, 24), dtype=float32)\n",
      "Tensor(\"Max:0\", shape=(?, 24), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "0.922222222222\n",
      "CPU times: user 54.8 s, sys: 1.63 s, total: 56.5 s\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def conv_model(X, y):\n",
    "    print('===============================')\n",
    "    print(X)\n",
    "    # get in format expected by conv2d\n",
    "    # (batch_size,width, height,color_channels)\n",
    "    # since our images are gray scale and 8x8 pixels\n",
    "    #   we define the last three elements as 8x8x1\n",
    "    # we don't know the batch size, so just let it \n",
    "    # figure that out from the input data (-1 designation)\n",
    "    X = tf.reshape(X, [-1, 8, 8, 1])\n",
    "    print(X)\n",
    "    \n",
    "    # now lets define the convolution\n",
    "    # here we are saying to find 24 different filter outputs from the image\n",
    "    # using a 4x4 weight kernel\n",
    "    features = layers.conv2d(inputs=X, \n",
    "                             num_outputs=24, \n",
    "                             kernel_size=[3, 3])\n",
    "    print(features)\n",
    "    \n",
    "    # take the max of each of the 24 filter outputs (lose spatial resolution)\n",
    "    features = tf.reduce_max(input_tensor=features, \n",
    "                             reduction_indices=[1, 2])\n",
    "    \n",
    "    print(features)\n",
    "    pred, loss = learn.models.logistic_regression(features, y)\n",
    "    print(pred)\n",
    "    print('===============================')\n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "# Create a classifier, train and predict.\n",
    "classifier = learn.TensorFlowEstimator(model_fn=conv_model, \n",
    "                                       n_classes=10, steps=1000, \n",
    "                                       learning_rate=0.05, batch_size=128)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/hzf28kx94nv2vp_fvfsfvkdw0000gn/T/tmp2xf0u028\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 8, 8, 1), dtype=float32)\n",
      "Tensor(\"Conv/Relu:0\", shape=(?, 8, 8, 12), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 4, 4, 12), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 192), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 8, 8, 1), dtype=float32)\n",
      "Tensor(\"Conv/Relu:0\", shape=(?, 8, 8, 12), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 4, 4, 12), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 192), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "0.986111111111\n",
      "CPU times: user 15.9 s, sys: 2.48 s, total: 18.3 s\n",
      "Wall time: 9.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def conv_model(X, y):\n",
    "    print('===============================')\n",
    "    print(X)\n",
    "    # get in format expected by conv2d\n",
    "    # (batch_size,width, height,color_channels)\n",
    "    # since our images are gray scale and 8x8 pixels\n",
    "    #   we define the last three elements as 8x8x1\n",
    "    # we don't know the batch size, so just let it \n",
    "    # figure that out from the input data (-1 designation)\n",
    "    img_wh = 8 # height and width of images\n",
    "    X = tf.reshape(X, [-1, img_wh, img_wh, 1])\n",
    "    print(X)\n",
    "    \n",
    "    # now lets define the convolution\n",
    "    # here we are saying to find n_out different filters from the image\n",
    "    # using 4x4 weight kernels\n",
    "    n_out = 12\n",
    "    features = layers.conv2d(inputs=X, \n",
    "                             num_outputs=n_out, \n",
    "                             kernel_size=[3, 3])\n",
    "    print(features)\n",
    "    \n",
    "    # pool the outputs of the filters \n",
    "    # stride controls downsampling weight\n",
    "    kernel = [1, 2, 2, 1]\n",
    "    stride = [1, 2, 2, 1]\n",
    "    features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "    print(features)\n",
    "    \n",
    "    # make the weights a column vector\n",
    "    n_rows = int(img_wh/stride[1])\n",
    "    n_cols = int(img_wh/stride[2])\n",
    "    features = tf.reshape(features,[-1, n_out*n_rows*n_cols])\n",
    "    print(features)\n",
    "    \n",
    "    # then make a fully connected layer with sigmoid nonlinearity \n",
    "    pred, loss = learn.models.logistic_regression(features, y)\n",
    "    print(pred)\n",
    "    print('===============================')\n",
    "    \n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "# Create a classifier, train and predict.\n",
    "classifier = learn.TensorFlowEstimator(model_fn=conv_model, \n",
    "                                       n_classes=10, steps=1500, \n",
    "                                       learning_rate=0.05, batch_size=128)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/hzf28kx94nv2vp_fvfsfvkdw0000gn/T/tmpkwawn5ch\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Conv/Relu:0\", shape=(?, 8, 8, 24), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 4, 4, 24), dtype=float32)\n",
      "Tensor(\"Conv_1/Relu:0\", shape=(?, 4, 4, 24), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 2, 2, 24), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 96), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Conv/Relu:0\", shape=(?, 8, 8, 24), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 4, 4, 24), dtype=float32)\n",
      "Tensor(\"Conv_1/Relu:0\", shape=(?, 4, 4, 24), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 2, 2, 24), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 96), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "0.988888888889\n",
      "CPU times: user 1min 20s, sys: 12.1 s, total: 1min 32s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make it deeper\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def conv_model(X, y):\n",
    "    print('===============================')\n",
    "    print(X)\n",
    "    # get in format expected by conv2d\n",
    "    # (batch_size,width, height,color_channels)\n",
    "    # since our images are gray scale and 8x8 pixels\n",
    "    #   we define the last three elements as 8x8x1\n",
    "    # we don't know the batch size, so just let it \n",
    "    # figure that out from the input data (-1 designation)\n",
    "    img_wh = 8 # height and width of images\n",
    "    features = tf.reshape(X, [-1, img_wh, img_wh, 1])\n",
    "    print(X)\n",
    "    \n",
    "    nlayers = 2\n",
    "    n_out = 24\n",
    "    for _ in range(nlayers):\n",
    "        # now lets define the convolution\n",
    "        # here we are saying to find n_out different filters from the image\n",
    "        # using 4x4 weight kernels\n",
    "        \n",
    "        features = layers.conv2d(inputs=features, \n",
    "                                 num_outputs=n_out, \n",
    "                                 kernel_size=[3, 3])\n",
    "        print(features)\n",
    "\n",
    "        # pool the outputs of the filters \n",
    "        # stride controls downsampling weight\n",
    "        kernel = [1, 2, 2, 1]\n",
    "        stride = [1, 2, 2, 1]\n",
    "        features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "        print(features)\n",
    "    \n",
    "    # make the weights a column vector\n",
    "    n_rows = int(img_wh/(stride[1]*nlayers))\n",
    "    n_cols = int(img_wh/(stride[2]*nlayers))\n",
    "    features = tf.reshape(features,[-1, n_out*n_rows*n_cols])\n",
    "    print(features)\n",
    "    \n",
    "    # then make a fully connected layer with sigmoid nonlinearity \n",
    "    pred, loss = learn.models.logistic_regression(features, y)\n",
    "    print(pred)\n",
    "    print('===============================')\n",
    "    \n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "# Create a classifier, train and predict.\n",
    "classifier = learn.TensorFlowEstimator(model_fn=conv_model, \n",
    "                                       n_classes=10, steps=2000, \n",
    "                                       learning_rate=0.05, batch_size=256)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/hzf28kx94nv2vp_fvfsfvkdw0000gn/T/tmp8cwy_ykc\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 8, 8, 1), dtype=float32)\n",
      "Tensor(\"Conv_1/Relu:0\", shape=(?, 4, 4, 24), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 2, 2, 24), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 96), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 8, 8), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 8, 8, 1), dtype=float32)\n",
      "Tensor(\"Conv_1/Relu:0\", shape=(?, 4, 4, 24), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 2, 2, 24), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 96), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "0.997222222222\n",
      "CPU times: user 1min 37s, sys: 14.8 s, total: 1min 52s\n",
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LeNet example (dumbed down to )\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def conv_model(X, y):\n",
    "    print('===============================')\n",
    "    print(X)\n",
    "    # get in format expected by conv2d\n",
    "    # (batch_size,width, height,color_channels)\n",
    "    # since our images are gray scale and 8x8 pixels\n",
    "    #   we define the last three elements as 8x8x1\n",
    "    # we don't know the batch size, so just let it \n",
    "    # figure that out from the input data (-1 designation)\n",
    "    img_wh = 8 # height and width of images\n",
    "    features = tf.reshape(X, [-1, img_wh, img_wh, 1])\n",
    "    print(features)\n",
    "    \n",
    "    nlayers = 1\n",
    "    n_out = 24\n",
    "    \n",
    "    features = layers.conv2d(inputs=features, \n",
    "                            num_outputs=n_out, \n",
    "                            kernel_size=[3, 3])\n",
    "    \n",
    "    kernel = [1, 2, 2, 1]\n",
    "    stride = [1, 2, 2, 1]\n",
    "    features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "    \n",
    "    n_out = 24\n",
    "    for _ in range(nlayers):\n",
    "        # now lets define the convolution\n",
    "        # here we are saying to find n_out different filters from the image\n",
    "        # using 4x4 weight kernels\n",
    "        \n",
    "        features = layers.conv2d(inputs=features, \n",
    "                                 num_outputs=n_out, \n",
    "                                 kernel_size=[2, 2])\n",
    "        print(features)\n",
    "\n",
    "        # pool the outputs of the filters \n",
    "        # no downsampling\n",
    "        kernel = [1, 2, 2, 1]\n",
    "        stride = [1, 2, 2, 1]\n",
    "        features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "        print(features)\n",
    "    \n",
    "    # make the weights a column vector\n",
    "    features = layers.flatten(features)\n",
    "    print(features)\n",
    "    \n",
    "    features = tf.nn.relu(features)\n",
    "    features = layers.stack(features, layers.fully_connected, [100])\n",
    "    features = tf.nn.relu(features)\n",
    "    features = layers.stack(features, layers.fully_connected, [100])\n",
    "    features = tf.nn.relu(features)\n",
    "    #features = tf.nn.sigmoid(features)\n",
    "    print(features)\n",
    "    \n",
    "    # then make a fully connected layer with sigmoid nonlinearity \n",
    "    pred, loss = learn.models.logistic_regression(features, y)\n",
    "    print(pred)\n",
    "    \n",
    "    print('===============================')\n",
    "    \n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "# Create a classifier, train and predict.\n",
    "classifier = learn.TensorFlowEstimator(model_fn=conv_model, \n",
    "                                       n_classes=10, steps=5000, \n",
    "                                       learning_rate=0.05, batch_size=128)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, columns: 784\n",
      "Rows: 10000, columns: 784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more data for handwriting recognition?\n",
    "# Let's use Raschka's implementation for using the mnist dataset:\n",
    "# https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, '%s-labels.idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images.idx3-ubyte' % kind)\n",
    "        \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    " \n",
    "    return images.astype(np.float32), labels.reshape((-1,1)).astype(np.int32)\n",
    "\n",
    "X_train, y_train = load_mnist('data/', kind='train')\n",
    "print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))\n",
    "\n",
    "X_test, y_test = load_mnist('data/', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n",
      "WARNING:tensorflow:load_variable (from tensorflow.contrib.learn.python.learn.utils.checkpoints) is deprecated and will be removed after 2016-08-22.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.framework.load_variable instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "CPU times: user 1min 31s, sys: 5.1 s, total: 1min 36s\n",
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "feature_columns = learn.infer_real_valued_columns_from_input(X_train)\n",
    "clf = learn.DNNClassifier(feature_columns=feature_columns, \n",
    "                          activation_fn=layers.nn.relu,\n",
    "                          hidden_units=[100,50,50], \n",
    "                          n_classes=10)\n",
    "\n",
    "clf.fit(X_train, y_train, batch_size=256, max_steps=5000)\n",
    "\n",
    "yhat = list(clf.predict(X_test, as_iterable=True))\n",
    "\n",
    "print(accuracy_score(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/hzf28kx94nv2vp_fvfsfvkdw0000gn/T/tmpgghfk10_\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv_1/Relu:0\", shape=(?, 14, 14, 24), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 24), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 1176), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv_1/Relu:0\", shape=(?, 14, 14, 24), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 24), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 1176), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "0.9865\n",
      "CPU times: user 6min 44s, sys: 47.4 s, total: 7min 32s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LeNet example (dumbed down to )\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def conv_model(X, y):\n",
    "    print('===============================')\n",
    "    print(X)\n",
    "    # get in format expected by conv2d\n",
    "    # (batch_size,width, height,color_channels)\n",
    "    # since our images are gray scale and 28x28 pixels\n",
    "    #   we define the last three elements as 28x28x1\n",
    "    # we don't know the batch size, so just let it \n",
    "    # figure that out from the input data (-1 designation)\n",
    "    img_wh = 28 # height and width of images\n",
    "    features = tf.reshape(X, [-1, img_wh, img_wh, 1])\n",
    "    print(features)\n",
    "    \n",
    "    nlayers = 1\n",
    "    n_out = 24\n",
    "    \n",
    "    features = layers.conv2d(inputs=features, \n",
    "                            num_outputs=n_out, \n",
    "                            kernel_size=[3, 3])\n",
    "    \n",
    "    kernel = [1, 2, 2, 1]\n",
    "    stride = [1, 2, 2, 1]\n",
    "    features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "    \n",
    "    n_out = 24\n",
    "    for _ in range(nlayers):\n",
    "        # now lets define the convolution\n",
    "        # here we are saying to find n_out different filters from the image\n",
    "        # using 4x4 weight kernels\n",
    "        \n",
    "        features = layers.conv2d(inputs=features, \n",
    "                                 num_outputs=n_out, \n",
    "                                 kernel_size=[2, 2])\n",
    "        print(features)\n",
    "\n",
    "        # pool the outputs of the filters \n",
    "        # no downsampling\n",
    "        kernel = [1, 2, 2, 1]\n",
    "        stride = [1, 2, 2, 1]\n",
    "        features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "        print(features)\n",
    "    \n",
    "    # make the weights a column vector\n",
    "    features = layers.flatten(features)\n",
    "    print(features)\n",
    "    \n",
    "    features = tf.nn.relu(features)\n",
    "    features = layers.stack(features, layers.fully_connected, [100])\n",
    "    features = tf.nn.relu(features)\n",
    "    features = layers.stack(features, layers.fully_connected, [100])\n",
    "    features = tf.nn.relu(features)\n",
    "    #features = tf.nn.sigmoid(features)\n",
    "    print(features)\n",
    "    \n",
    "    # then make a fully connected layer with sigmoid nonlinearity \n",
    "    pred, loss = learn.models.logistic_regression(features, y)\n",
    "    print(pred)\n",
    "    \n",
    "    print('===============================')\n",
    "    \n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "# Create a classifier, train and predict.\n",
    "classifier = learn.TensorFlowEstimator(model_fn=conv_model, \n",
    "                                       n_classes=10, steps=2000, \n",
    "                                       learning_rate=0.05, batch_size=128)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = accuracy_score(y_test, classifier.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/hzf28kx94nv2vp_fvfsfvkdw0000gn/T/tmph06_z2qa\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 3136), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "===============================\n",
      "Tensor(\"input:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 3136), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"logistic_regression/softmax_classifier/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "===============================\n",
      "0.9926\n",
      "CPU times: user 4h 1min 13s, sys: 31min 8s, total: 4h 32min 21s\n",
      "Wall time: 1h 31min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Copy TensorFlow Architecture from \n",
    "#   Deep MNIST for experts\n",
    "#   https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def conv_model(X, y):\n",
    "    print('===============================')\n",
    "    print(X)\n",
    "    # get in format expected by conv2d\n",
    "    # (batch_size,width, height,color_channels)\n",
    "    # since our images are gray scale and 28x28 pixels\n",
    "    #   we define the last three elements as 28x28x1\n",
    "    # we don't know the batch size, so just let it \n",
    "    # figure that out from the input data (-1 designation)\n",
    "    img_wh = 28 # height and width of images\n",
    "    features = tf.reshape(X, [-1, img_wh, img_wh, 1])\n",
    "    print(features)\n",
    "    \n",
    "    # create 32 filters of 5x5 size \n",
    "    n_out = 32\n",
    "    kernel = [5,5]\n",
    "    features = layers.conv2d(inputs=features, \n",
    "                            num_outputs=n_out, \n",
    "                            kernel_size=kernel)\n",
    "    \n",
    "    # add a bias and pass through relu (for concentrated gradients)\n",
    "    features = tf.nn.relu(layers.bias_add(features))\n",
    "    \n",
    "    # 2x2 max pool to reduce image size to 14x14\n",
    "    kernel = [1, 2, 2, 1]\n",
    "    stride = [1, 2, 2, 1]\n",
    "    features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "    \n",
    "    # create 64 filters of 5x5 size\n",
    "    n_out = 64\n",
    "    kernel = [5,5]\n",
    "    features = layers.conv2d(inputs=features, \n",
    "                            num_outputs=n_out, \n",
    "                            kernel_size=kernel)\n",
    "    \n",
    "    # add a bias and pass through relu (for concentrated gradients)\n",
    "    features = tf.nn.relu(layers.bias_add(features))\n",
    "    \n",
    "    # 2x2 max pool to reduce image size to 7x7\n",
    "    kernel = [1, 2, 2, 1]\n",
    "    stride = [1, 2, 2, 1]\n",
    "    features = tf.nn.max_pool(features, ksize=kernel,strides=stride, padding='SAME')\n",
    "    \n",
    "\n",
    "    # make the weights a column vector, 7x7x64 = 3136\n",
    "    features = layers.flatten(features)\n",
    "    print(features)\n",
    "    \n",
    "    # pass through fully connected layer with 1024 hidden neurons, W=3136x1024\n",
    "    features = layers.stack(features, layers.fully_connected, [1024])\n",
    "    \n",
    "    # add bias and pass through relu\n",
    "    features = tf.nn.relu(layers.bias_add(features))\n",
    "    print(features)\n",
    "    \n",
    "    # then make a fully connected layer with bias and sigmoid nonlinearity \n",
    "    #  which... is... just logistic regression with one versus all\n",
    "    pred, loss = learn.models.logistic_regression(features, y)\n",
    "    print(pred)\n",
    "    \n",
    "    print('===============================')\n",
    "    \n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "# Create a classifier, train and predict.\n",
    "classifier = learn.TensorFlowEstimator(model_fn=conv_model, \n",
    "                                       n_classes=10, steps=20000, \n",
    "                                       learning_rate=0.05, batch_size=64)\n",
    "\n",
    "# this operation can take a little while to complete\n",
    "#   Google says it should take about 30 minutes, but \n",
    "#   my machine took a lot longer...\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# now predict the outcome\n",
    "score = accuracy_score(y_test, classifier.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [MLEnv]",
   "language": "python",
   "name": "Python [MLEnv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
